{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Se importan las librerias requeridas"
      ],
      "metadata": {
        "id": "E9R5zyv1epHb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DLwthoaweRB6"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ruta_del_archivo = 'elquijote.txt'\n",
        "try:\n",
        "    with open(ruta_del_archivo, 'r') as archivo:\n",
        "        content = archivo.read()\n",
        "        print(content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"El archivo '{ruta_del_archivo}' fue encontrado.\")\n",
        "except Exception as e:\n",
        "    print(f\"Ocurrió un error al leer el archivo: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOuSs_uCnFNz",
        "outputId": "78957dd2-39d4-4bf2-e1d9-09cbd1ab4c45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "El archivo 'elquijote.txt' fue encontrado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data(file_name):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        file_name: string, path to the text file.\n",
        "    Output:\n",
        "        words: list of words contained in the file.\n",
        "    \"\"\"\n",
        "    words = []\n",
        "\n",
        "    with open(file_name, \"r\", encoding=\"utf8\") as file:\n",
        "        text = file.read()\n",
        "        text = text.lower()\n",
        "        text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "        words = re.findall(r'\\w+', text)\n",
        "        word = text.split()\n",
        "\n",
        "    return words"
      ],
      "metadata": {
        "id": "VU9T7J36tWw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = process_data(\"/content/elquijote.txt\")\n",
        "print(\"el numero de palabras es: {}\".format(len(words)))\n",
        "vocab = set(words)\n",
        "print(\"el vocabulario (numero de palabras unicas) es de: {}\".format(len(vocab)))\n",
        "print(\"algunas de las palabras son: {}\".format(words[500:550]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDfVQN47tb4i",
        "outputId": "07aa9636-5880-418b-898d-dee9e17e4362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "el numero de palabras es: 384442\n",
            "el vocabulario (numero de palabras unicas) es de: 23631\n",
            "algunas de las palabras son: ['día', 'de', 'la', 'data', 'desta', 'nuestra', 'cédula', 'so', 'pena', 'que', 'la', 'persona', 'o', 'personas', 'que', 'sin', 'tener', 'vuestro', 'poder', 'lo', 'imprimiere', 'o', 'vendiere', 'o', 'hiciere', 'imprimir', 'o', 'vender', 'por', 'el', 'mesmo', 'caso', 'pierda', 'la', 'impresión', 'que', 'hiciere', 'con', 'los', 'moldes', 'y', 'aparejos', 'della', 'y', 'más', 'incurra', 'en', 'pena', 'de', 'cincuenta']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_count(word_l):\n",
        "    '''\n",
        "    Input:\n",
        "        word_l: a set of words representing the corpus.\n",
        "    Output:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    '''\n",
        "\n",
        "    word_count_dict = {}  # fill this with word counts\n",
        "    ### START CODE HERE\n",
        "\n",
        "    # Itera sobre cada palabra en la lista\n",
        "    for word in word_l:\n",
        "        # Si la palabra ya está en el diccionario, incrementa su contador\n",
        "        if word in word_count_dict:\n",
        "            word_count_dict[word] += 1\n",
        "        # Si no, agrégala al diccionario con un contador de 1\n",
        "        else:\n",
        "            word_count_dict[word] = 1\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "    return word_count_dict"
      ],
      "metadata": {
        "id": "zMcAZs3qxqIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_count_dict = get_count(words)\n",
        "print(\"existen {} keys\".format(len(word_count_dict)))\n",
        "print(\"las veces que se menciona dulcinea: {}\".format(word_count_dict.get(\"dulcinea\", 0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMblN4KMxyRw",
        "outputId": "2561b3af-40c1-48f9-9afe-572d937fd372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "existen 23631 keys\n",
            "las veces que se menciona dulcinea: 282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_probs(word_count_dict):\n",
        "    '''\n",
        "    Input:\n",
        "        word_count_dict: The wordcount dictionary where key is the word and value is its frequency.\n",
        "    Output:\n",
        "        probs: A dictionary where key is the word and value is its probability.\n",
        "    '''\n",
        "    probs = {}\n",
        "    # 1. Calcular el total de palabras (sumando todas las frecuencias)\n",
        "    total_words = sum(word_count_dict.values())\n",
        "\n",
        "    # 2. Iterar sobre el diccionario de recuentos para calcular la probabilidad de cada palabra\n",
        "    for word, count in word_count_dict.items():\n",
        "        probs[word] = count / total_words\n",
        "\n",
        "    return probs"
      ],
      "metadata": {
        "id": "BAhiLAiF09ML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs = get_probs(word_count_dict)\n",
        "print(\"numero de total de palabras: {}\".format(len(probs)))\n",
        "print(\"P(dulcinea) es: {:.4f}\".format(probs[\"dulcinea\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU8M2uvK1awc",
        "outputId": "2d6635c6-549b-45d6-a935-ac689e02752f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de total de palabras: 23631\n",
            "P(dulcinea) es: 0.0007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the string/word for which you will generate all possible words\n",
        "                in the vocabulary which have 1 missing character\n",
        "    Output:\n",
        "        delete_l: a list of all possible strings obtained by deleting 1 character from word\n",
        "    '''\n",
        "\n",
        "    delete_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    delete_l = [L + R[1:] for L, R in split_l if R]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"input word {word}, \\nsplit_l = {split_l}, \\ndelete_l = {delete_l}\")\n",
        "\n",
        "    return  delete_l"
      ],
      "metadata": {
        "id": "L29WZB324K02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "delete_word_l = delete_letter(word=\"oir\", verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODPaDDlJ4OxO",
        "outputId": "3bbf7077-07e4-4f92-f87f-2cbe78d90fa4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input word oir, \n",
            "split_l = [('', 'oir'), ('o', 'ir'), ('oi', 'r'), ('oir', '')], \n",
            "delete_l = ['ir', 'or', 'oi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def switch_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: input string\n",
        "     Output:\n",
        "        switches: a list of all possible strings with one adjacent charater switched\n",
        "    '''\n",
        "\n",
        "    switch_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word))]\n",
        "    switch_l = [L + R[1] + R[0] + R[2:] for L, R in split_l if len(R)>=2]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nswitch_l = {switch_l}\")\n",
        "\n",
        "    return switch_l\n"
      ],
      "metadata": {
        "id": "qtS4NR6d4ejn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "switch_word_l = switch_letter(word=\"comer\", verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5o3bvaYx4h-q",
        "outputId": "7a5564f1-d893-47e8-b25e-96458bb4c2a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = comer \n",
            "split_l = [('', 'comer'), ('c', 'omer'), ('co', 'mer'), ('com', 'er'), ('come', 'r')] \n",
            "switch_l = ['ocmer', 'cmoer', 'coemr', 'comre']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def replace_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        replaces: a list of all possible strings where we replaced one letter from the original word.\n",
        "    '''\n",
        "\n",
        "    letters = string.ascii_lowercase # 'abcdefghijklmnopqrstuvwxyz'\n",
        "\n",
        "    replace_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Divide la palabra en dos partes, justo antes de cada letra\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    # Itera sobre cada división y cada letra del alfabeto para generar nuevas palabras\n",
        "    replaces = [L + c + R[1:] for L, R in split_l if R for c in letters]\n",
        "    replace_l = [L + letter + R[1:] for L, R in split_l if R for letter in letters]\n",
        "    # La List Comprension anterior incluye la palabra original (ej. 'fuego' si reemplazas 'f' con 'f')\n",
        "    replaces = [w for w in replaces if w != word]\n",
        "    replace_set = set(replace_l)\n",
        "    replace_set.discard(word)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # turn the set back into a list and sort it, for easier viewing\n",
        "    replace_l = sorted(list(replace_set))\n",
        "\n",
        "\n",
        "    if verbose: print(f\"Input word = {word} \\nsplit_l = {split_l} \\nreplace_l {replace_l}\")\n",
        "\n",
        "    return replace_l"
      ],
      "metadata": {
        "id": "2VPsJrFK6dEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "replace_l = replace_letter(word='fuego', verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJgSuQwh6rjI",
        "outputId": "e9d67376-7f1a-438f-eb12-f7d31d235d32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word = fuego \n",
            "split_l = [('', 'fuego'), ('f', 'uego'), ('fu', 'ego'), ('fue', 'go'), ('fueg', 'o'), ('fuego', '')] \n",
            "replace_l ['auego', 'buego', 'cuego', 'duego', 'euego', 'faego', 'fbego', 'fcego', 'fdego', 'feego', 'ffego', 'fgego', 'fhego', 'fiego', 'fjego', 'fkego', 'flego', 'fmego', 'fnego', 'foego', 'fpego', 'fqego', 'frego', 'fsego', 'ftego', 'fuago', 'fubgo', 'fucgo', 'fudgo', 'fueao', 'fuebo', 'fueco', 'fuedo', 'fueeo', 'fuefo', 'fuega', 'fuegb', 'fuegc', 'fuegd', 'fuege', 'fuegf', 'fuegg', 'fuegh', 'fuegi', 'fuegj', 'fuegk', 'fuegl', 'fuegm', 'fuegn', 'fuegp', 'fuegq', 'fuegr', 'fuegs', 'fuegt', 'fuegu', 'fuegv', 'fuegw', 'fuegx', 'fuegy', 'fuegz', 'fueho', 'fueio', 'fuejo', 'fueko', 'fuelo', 'fuemo', 'fueno', 'fueoo', 'fuepo', 'fueqo', 'fuero', 'fueso', 'fueto', 'fueuo', 'fuevo', 'fuewo', 'fuexo', 'fueyo', 'fuezo', 'fufgo', 'fuggo', 'fuhgo', 'fuigo', 'fujgo', 'fukgo', 'fulgo', 'fumgo', 'fungo', 'fuogo', 'fupgo', 'fuqgo', 'furgo', 'fusgo', 'futgo', 'fuugo', 'fuvgo', 'fuwgo', 'fuxgo', 'fuygo', 'fuzgo', 'fvego', 'fwego', 'fxego', 'fyego', 'fzego', 'guego', 'huego', 'iuego', 'juego', 'kuego', 'luego', 'muego', 'nuego', 'ouego', 'puego', 'quego', 'ruego', 'suego', 'tuego', 'uuego', 'vuego', 'wuego', 'xuego', 'yuego', 'zuego']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_letter(word, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        inserts: a set of all possible strings with one new letter inserted at every offset\n",
        "    '''\n",
        "    letters = 'abcdefghijklmnopqrstuvwxyz'\n",
        "    insert_l = []\n",
        "    split_l = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    # Diviimos todas las palabras posibles de prefijos y sufijos\n",
        "    split_l = [(word[:i], word[i:]) for i in range(len(word)+1)]\n",
        "    # Utiliza un bucle anidadoy construye la nueva palabra uniendo el prefijo, la letra insertada y el sufijo\n",
        "    insert_l = [L + c + R for L, R in split_l for c in letters]\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose: print(f\"Input word {word} \\nsplit_l = {split_l} \\ninsert_l = {insert_l}\")\n",
        "\n",
        "    return insert_l"
      ],
      "metadata": {
        "id": "_x7RnHUe_BMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "insert_l = insert_letter('ir', True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4YnWI-A_N09",
        "outputId": "26b6ec24-c97d-49b9-e551-dcfc0e5749ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input word ir \n",
            "split_l = [('', 'ir'), ('i', 'r'), ('ir', '')] \n",
            "insert_l = ['air', 'bir', 'cir', 'dir', 'eir', 'fir', 'gir', 'hir', 'iir', 'jir', 'kir', 'lir', 'mir', 'nir', 'oir', 'pir', 'qir', 'rir', 'sir', 'tir', 'uir', 'vir', 'wir', 'xir', 'yir', 'zir', 'iar', 'ibr', 'icr', 'idr', 'ier', 'ifr', 'igr', 'ihr', 'iir', 'ijr', 'ikr', 'ilr', 'imr', 'inr', 'ior', 'ipr', 'iqr', 'irr', 'isr', 'itr', 'iur', 'ivr', 'iwr', 'ixr', 'iyr', 'izr', 'ira', 'irb', 'irc', 'ird', 'ire', 'irf', 'irg', 'irh', 'iri', 'irj', 'irk', 'irl', 'irm', 'irn', 'iro', 'irp', 'irq', 'irr', 'irs', 'irt', 'iru', 'irv', 'irw', 'irx', 'iry', 'irz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_one_letter(word, allow_switches = True):\n",
        "    \"\"\"\n",
        "    Input:\n",
        "        word: the string/word for which we will generate all possible wordsthat are one edit away.\n",
        "    Output:\n",
        "        edit_one_set: a set of words with one possible edit. Please return a set. and not a list.\n",
        "    \"\"\"\n",
        "\n",
        "    edit_one_set = set()\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "    edit_one_set.update(delete_letter(word))\n",
        "\n",
        "    if allow_switches:\n",
        "        edit_one_set.update(switch_letter(word))\n",
        "\n",
        "    edit_one_set.update(replace_letter(word))\n",
        "\n",
        "    edit_one_set.update(insert_letter(word))\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # return this as a set and not a list\n",
        "    return edit_one_set\n"
      ],
      "metadata": {
        "id": "Z-YMMEeUDUqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"ir\"\n",
        "tmp_edit_one_set = edit_one_letter(tmp_word)\n",
        "# turn this into a list to sort it, in order to view it\n",
        "tmp_edit_one_l = sorted(list(tmp_edit_one_set))\n",
        "print(tmp_edit_one_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0nlZunMDb31",
        "outputId": "6b364a38-b6ba-4689-c048-689e0b00f0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['air', 'ar', 'bir', 'br', 'cir', 'cr', 'dir', 'dr', 'eir', 'er', 'fir', 'fr', 'gir', 'gr', 'hir', 'hr', 'i', 'ia', 'iar', 'ib', 'ibr', 'ic', 'icr', 'id', 'idr', 'ie', 'ier', 'if', 'ifr', 'ig', 'igr', 'ih', 'ihr', 'ii', 'iir', 'ij', 'ijr', 'ik', 'ikr', 'il', 'ilr', 'im', 'imr', 'in', 'inr', 'io', 'ior', 'ip', 'ipr', 'iq', 'iqr', 'ira', 'irb', 'irc', 'ird', 'ire', 'irf', 'irg', 'irh', 'iri', 'irj', 'irk', 'irl', 'irm', 'irn', 'iro', 'irp', 'irq', 'irr', 'irs', 'irt', 'iru', 'irv', 'irw', 'irx', 'iry', 'irz', 'is', 'isr', 'it', 'itr', 'iu', 'iur', 'iv', 'ivr', 'iw', 'iwr', 'ix', 'ixr', 'iy', 'iyr', 'iz', 'izr', 'jir', 'jr', 'kir', 'kr', 'lir', 'lr', 'mir', 'mr', 'nir', 'nr', 'oir', 'or', 'pir', 'pr', 'qir', 'qr', 'r', 'ri', 'rir', 'rr', 'sir', 'sr', 'tir', 'tr', 'uir', 'ur', 'vir', 'vr', 'wir', 'wr', 'xir', 'xr', 'yir', 'yr', 'zir', 'zr']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def edit_two_letters(word, allow_switches = True):\n",
        "    '''\n",
        "    Input:\n",
        "        word: the input string/word\n",
        "    Output:\n",
        "        edit_two_set: a set of strings with all possible two edits\n",
        "    '''\n",
        "\n",
        "    edit_two_set = set()\n",
        "\n",
        "    one_set = edit_one_letter(word, allow_switches = allow_switches)\n",
        "    for word in one_set:\n",
        "        if word:\n",
        "            edit_two = edit_one_letter(word, allow_switches = allow_switches)\n",
        "            edit_two_set.update(edit_two)\n",
        "\n",
        "    # El 'return' debe estar alineado con la variable 'edit_two_set'\n",
        "    return edit_two_set"
      ],
      "metadata": {
        "id": "8V1NngzxD4c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tmp_word = \"a\"\n",
        "tmp_edit_two_set = edit_two_letters(\"a\")\n",
        "tmp_edit_two_l = sorted(list(tmp_edit_two_set))\n",
        "print(tmp_edit_two_l)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plXih2xFGCUV",
        "outputId": "527872c1-012d-42be-dd1f-ae25e419df91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'a', 'aa', 'aaa', 'aab', 'aac', 'aad', 'aae', 'aaf', 'aag', 'aah', 'aai', 'aaj', 'aak', 'aal', 'aam', 'aan', 'aao', 'aap', 'aaq', 'aar', 'aas', 'aat', 'aau', 'aav', 'aaw', 'aax', 'aay', 'aaz', 'ab', 'aba', 'abb', 'abc', 'abd', 'abe', 'abf', 'abg', 'abh', 'abi', 'abj', 'abk', 'abl', 'abm', 'abn', 'abo', 'abp', 'abq', 'abr', 'abs', 'abt', 'abu', 'abv', 'abw', 'abx', 'aby', 'abz', 'ac', 'aca', 'acb', 'acc', 'acd', 'ace', 'acf', 'acg', 'ach', 'aci', 'acj', 'ack', 'acl', 'acm', 'acn', 'aco', 'acp', 'acq', 'acr', 'acs', 'act', 'acu', 'acv', 'acw', 'acx', 'acy', 'acz', 'ad', 'ada', 'adb', 'adc', 'add', 'ade', 'adf', 'adg', 'adh', 'adi', 'adj', 'adk', 'adl', 'adm', 'adn', 'ado', 'adp', 'adq', 'adr', 'ads', 'adt', 'adu', 'adv', 'adw', 'adx', 'ady', 'adz', 'ae', 'aea', 'aeb', 'aec', 'aed', 'aee', 'aef', 'aeg', 'aeh', 'aei', 'aej', 'aek', 'ael', 'aem', 'aen', 'aeo', 'aep', 'aeq', 'aer', 'aes', 'aet', 'aeu', 'aev', 'aew', 'aex', 'aey', 'aez', 'af', 'afa', 'afb', 'afc', 'afd', 'afe', 'aff', 'afg', 'afh', 'afi', 'afj', 'afk', 'afl', 'afm', 'afn', 'afo', 'afp', 'afq', 'afr', 'afs', 'aft', 'afu', 'afv', 'afw', 'afx', 'afy', 'afz', 'ag', 'aga', 'agb', 'agc', 'agd', 'age', 'agf', 'agg', 'agh', 'agi', 'agj', 'agk', 'agl', 'agm', 'agn', 'ago', 'agp', 'agq', 'agr', 'ags', 'agt', 'agu', 'agv', 'agw', 'agx', 'agy', 'agz', 'ah', 'aha', 'ahb', 'ahc', 'ahd', 'ahe', 'ahf', 'ahg', 'ahh', 'ahi', 'ahj', 'ahk', 'ahl', 'ahm', 'ahn', 'aho', 'ahp', 'ahq', 'ahr', 'ahs', 'aht', 'ahu', 'ahv', 'ahw', 'ahx', 'ahy', 'ahz', 'ai', 'aia', 'aib', 'aic', 'aid', 'aie', 'aif', 'aig', 'aih', 'aii', 'aij', 'aik', 'ail', 'aim', 'ain', 'aio', 'aip', 'aiq', 'air', 'ais', 'ait', 'aiu', 'aiv', 'aiw', 'aix', 'aiy', 'aiz', 'aj', 'aja', 'ajb', 'ajc', 'ajd', 'aje', 'ajf', 'ajg', 'ajh', 'aji', 'ajj', 'ajk', 'ajl', 'ajm', 'ajn', 'ajo', 'ajp', 'ajq', 'ajr', 'ajs', 'ajt', 'aju', 'ajv', 'ajw', 'ajx', 'ajy', 'ajz', 'ak', 'aka', 'akb', 'akc', 'akd', 'ake', 'akf', 'akg', 'akh', 'aki', 'akj', 'akk', 'akl', 'akm', 'akn', 'ako', 'akp', 'akq', 'akr', 'aks', 'akt', 'aku', 'akv', 'akw', 'akx', 'aky', 'akz', 'al', 'ala', 'alb', 'alc', 'ald', 'ale', 'alf', 'alg', 'alh', 'ali', 'alj', 'alk', 'all', 'alm', 'aln', 'alo', 'alp', 'alq', 'alr', 'als', 'alt', 'alu', 'alv', 'alw', 'alx', 'aly', 'alz', 'am', 'ama', 'amb', 'amc', 'amd', 'ame', 'amf', 'amg', 'amh', 'ami', 'amj', 'amk', 'aml', 'amm', 'amn', 'amo', 'amp', 'amq', 'amr', 'ams', 'amt', 'amu', 'amv', 'amw', 'amx', 'amy', 'amz', 'an', 'ana', 'anb', 'anc', 'and', 'ane', 'anf', 'ang', 'anh', 'ani', 'anj', 'ank', 'anl', 'anm', 'ann', 'ano', 'anp', 'anq', 'anr', 'ans', 'ant', 'anu', 'anv', 'anw', 'anx', 'any', 'anz', 'ao', 'aoa', 'aob', 'aoc', 'aod', 'aoe', 'aof', 'aog', 'aoh', 'aoi', 'aoj', 'aok', 'aol', 'aom', 'aon', 'aoo', 'aop', 'aoq', 'aor', 'aos', 'aot', 'aou', 'aov', 'aow', 'aox', 'aoy', 'aoz', 'ap', 'apa', 'apb', 'apc', 'apd', 'ape', 'apf', 'apg', 'aph', 'api', 'apj', 'apk', 'apl', 'apm', 'apn', 'apo', 'app', 'apq', 'apr', 'aps', 'apt', 'apu', 'apv', 'apw', 'apx', 'apy', 'apz', 'aq', 'aqa', 'aqb', 'aqc', 'aqd', 'aqe', 'aqf', 'aqg', 'aqh', 'aqi', 'aqj', 'aqk', 'aql', 'aqm', 'aqn', 'aqo', 'aqp', 'aqq', 'aqr', 'aqs', 'aqt', 'aqu', 'aqv', 'aqw', 'aqx', 'aqy', 'aqz', 'ar', 'ara', 'arb', 'arc', 'ard', 'are', 'arf', 'arg', 'arh', 'ari', 'arj', 'ark', 'arl', 'arm', 'arn', 'aro', 'arp', 'arq', 'arr', 'ars', 'art', 'aru', 'arv', 'arw', 'arx', 'ary', 'arz', 'as', 'asa', 'asb', 'asc', 'asd', 'ase', 'asf', 'asg', 'ash', 'asi', 'asj', 'ask', 'asl', 'asm', 'asn', 'aso', 'asp', 'asq', 'asr', 'ass', 'ast', 'asu', 'asv', 'asw', 'asx', 'asy', 'asz', 'at', 'ata', 'atb', 'atc', 'atd', 'ate', 'atf', 'atg', 'ath', 'ati', 'atj', 'atk', 'atl', 'atm', 'atn', 'ato', 'atp', 'atq', 'atr', 'ats', 'att', 'atu', 'atv', 'atw', 'atx', 'aty', 'atz', 'au', 'aua', 'aub', 'auc', 'aud', 'aue', 'auf', 'aug', 'auh', 'aui', 'auj', 'auk', 'aul', 'aum', 'aun', 'auo', 'aup', 'auq', 'aur', 'aus', 'aut', 'auu', 'auv', 'auw', 'aux', 'auy', 'auz', 'av', 'ava', 'avb', 'avc', 'avd', 'ave', 'avf', 'avg', 'avh', 'avi', 'avj', 'avk', 'avl', 'avm', 'avn', 'avo', 'avp', 'avq', 'avr', 'avs', 'avt', 'avu', 'avv', 'avw', 'avx', 'avy', 'avz', 'aw', 'awa', 'awb', 'awc', 'awd', 'awe', 'awf', 'awg', 'awh', 'awi', 'awj', 'awk', 'awl', 'awm', 'awn', 'awo', 'awp', 'awq', 'awr', 'aws', 'awt', 'awu', 'awv', 'aww', 'awx', 'awy', 'awz', 'ax', 'axa', 'axb', 'axc', 'axd', 'axe', 'axf', 'axg', 'axh', 'axi', 'axj', 'axk', 'axl', 'axm', 'axn', 'axo', 'axp', 'axq', 'axr', 'axs', 'axt', 'axu', 'axv', 'axw', 'axx', 'axy', 'axz', 'ay', 'aya', 'ayb', 'ayc', 'ayd', 'aye', 'ayf', 'ayg', 'ayh', 'ayi', 'ayj', 'ayk', 'ayl', 'aym', 'ayn', 'ayo', 'ayp', 'ayq', 'ayr', 'ays', 'ayt', 'ayu', 'ayv', 'ayw', 'ayx', 'ayy', 'ayz', 'az', 'aza', 'azb', 'azc', 'azd', 'aze', 'azf', 'azg', 'azh', 'azi', 'azj', 'azk', 'azl', 'azm', 'azn', 'azo', 'azp', 'azq', 'azr', 'azs', 'azt', 'azu', 'azv', 'azw', 'azx', 'azy', 'azz', 'b', 'ba', 'baa', 'bab', 'bac', 'bad', 'bae', 'baf', 'bag', 'bah', 'bai', 'baj', 'bak', 'bal', 'bam', 'ban', 'bao', 'bap', 'baq', 'bar', 'bas', 'bat', 'bau', 'bav', 'baw', 'bax', 'bay', 'baz', 'bb', 'bba', 'bc', 'bca', 'bd', 'bda', 'be', 'bea', 'bf', 'bfa', 'bg', 'bga', 'bh', 'bha', 'bi', 'bia', 'bj', 'bja', 'bk', 'bka', 'bl', 'bla', 'bm', 'bma', 'bn', 'bna', 'bo', 'boa', 'bp', 'bpa', 'bq', 'bqa', 'br', 'bra', 'bs', 'bsa', 'bt', 'bta', 'bu', 'bua', 'bv', 'bva', 'bw', 'bwa', 'bx', 'bxa', 'by', 'bya', 'bz', 'bza', 'c', 'ca', 'caa', 'cab', 'cac', 'cad', 'cae', 'caf', 'cag', 'cah', 'cai', 'caj', 'cak', 'cal', 'cam', 'can', 'cao', 'cap', 'caq', 'car', 'cas', 'cat', 'cau', 'cav', 'caw', 'cax', 'cay', 'caz', 'cb', 'cba', 'cc', 'cca', 'cd', 'cda', 'ce', 'cea', 'cf', 'cfa', 'cg', 'cga', 'ch', 'cha', 'ci', 'cia', 'cj', 'cja', 'ck', 'cka', 'cl', 'cla', 'cm', 'cma', 'cn', 'cna', 'co', 'coa', 'cp', 'cpa', 'cq', 'cqa', 'cr', 'cra', 'cs', 'csa', 'ct', 'cta', 'cu', 'cua', 'cv', 'cva', 'cw', 'cwa', 'cx', 'cxa', 'cy', 'cya', 'cz', 'cza', 'd', 'da', 'daa', 'dab', 'dac', 'dad', 'dae', 'daf', 'dag', 'dah', 'dai', 'daj', 'dak', 'dal', 'dam', 'dan', 'dao', 'dap', 'daq', 'dar', 'das', 'dat', 'dau', 'dav', 'daw', 'dax', 'day', 'daz', 'db', 'dba', 'dc', 'dca', 'dd', 'dda', 'de', 'dea', 'df', 'dfa', 'dg', 'dga', 'dh', 'dha', 'di', 'dia', 'dj', 'dja', 'dk', 'dka', 'dl', 'dla', 'dm', 'dma', 'dn', 'dna', 'do', 'doa', 'dp', 'dpa', 'dq', 'dqa', 'dr', 'dra', 'ds', 'dsa', 'dt', 'dta', 'du', 'dua', 'dv', 'dva', 'dw', 'dwa', 'dx', 'dxa', 'dy', 'dya', 'dz', 'dza', 'e', 'ea', 'eaa', 'eab', 'eac', 'ead', 'eae', 'eaf', 'eag', 'eah', 'eai', 'eaj', 'eak', 'eal', 'eam', 'ean', 'eao', 'eap', 'eaq', 'ear', 'eas', 'eat', 'eau', 'eav', 'eaw', 'eax', 'eay', 'eaz', 'eb', 'eba', 'ec', 'eca', 'ed', 'eda', 'ee', 'eea', 'ef', 'efa', 'eg', 'ega', 'eh', 'eha', 'ei', 'eia', 'ej', 'eja', 'ek', 'eka', 'el', 'ela', 'em', 'ema', 'en', 'ena', 'eo', 'eoa', 'ep', 'epa', 'eq', 'eqa', 'er', 'era', 'es', 'esa', 'et', 'eta', 'eu', 'eua', 'ev', 'eva', 'ew', 'ewa', 'ex', 'exa', 'ey', 'eya', 'ez', 'eza', 'f', 'fa', 'faa', 'fab', 'fac', 'fad', 'fae', 'faf', 'fag', 'fah', 'fai', 'faj', 'fak', 'fal', 'fam', 'fan', 'fao', 'fap', 'faq', 'far', 'fas', 'fat', 'fau', 'fav', 'faw', 'fax', 'fay', 'faz', 'fb', 'fba', 'fc', 'fca', 'fd', 'fda', 'fe', 'fea', 'ff', 'ffa', 'fg', 'fga', 'fh', 'fha', 'fi', 'fia', 'fj', 'fja', 'fk', 'fka', 'fl', 'fla', 'fm', 'fma', 'fn', 'fna', 'fo', 'foa', 'fp', 'fpa', 'fq', 'fqa', 'fr', 'fra', 'fs', 'fsa', 'ft', 'fta', 'fu', 'fua', 'fv', 'fva', 'fw', 'fwa', 'fx', 'fxa', 'fy', 'fya', 'fz', 'fza', 'g', 'ga', 'gaa', 'gab', 'gac', 'gad', 'gae', 'gaf', 'gag', 'gah', 'gai', 'gaj', 'gak', 'gal', 'gam', 'gan', 'gao', 'gap', 'gaq', 'gar', 'gas', 'gat', 'gau', 'gav', 'gaw', 'gax', 'gay', 'gaz', 'gb', 'gba', 'gc', 'gca', 'gd', 'gda', 'ge', 'gea', 'gf', 'gfa', 'gg', 'gga', 'gh', 'gha', 'gi', 'gia', 'gj', 'gja', 'gk', 'gka', 'gl', 'gla', 'gm', 'gma', 'gn', 'gna', 'go', 'goa', 'gp', 'gpa', 'gq', 'gqa', 'gr', 'gra', 'gs', 'gsa', 'gt', 'gta', 'gu', 'gua', 'gv', 'gva', 'gw', 'gwa', 'gx', 'gxa', 'gy', 'gya', 'gz', 'gza', 'h', 'ha', 'haa', 'hab', 'hac', 'had', 'hae', 'haf', 'hag', 'hah', 'hai', 'haj', 'hak', 'hal', 'ham', 'han', 'hao', 'hap', 'haq', 'har', 'has', 'hat', 'hau', 'hav', 'haw', 'hax', 'hay', 'haz', 'hb', 'hba', 'hc', 'hca', 'hd', 'hda', 'he', 'hea', 'hf', 'hfa', 'hg', 'hga', 'hh', 'hha', 'hi', 'hia', 'hj', 'hja', 'hk', 'hka', 'hl', 'hla', 'hm', 'hma', 'hn', 'hna', 'ho', 'hoa', 'hp', 'hpa', 'hq', 'hqa', 'hr', 'hra', 'hs', 'hsa', 'ht', 'hta', 'hu', 'hua', 'hv', 'hva', 'hw', 'hwa', 'hx', 'hxa', 'hy', 'hya', 'hz', 'hza', 'i', 'ia', 'iaa', 'iab', 'iac', 'iad', 'iae', 'iaf', 'iag', 'iah', 'iai', 'iaj', 'iak', 'ial', 'iam', 'ian', 'iao', 'iap', 'iaq', 'iar', 'ias', 'iat', 'iau', 'iav', 'iaw', 'iax', 'iay', 'iaz', 'ib', 'iba', 'ic', 'ica', 'id', 'ida', 'ie', 'iea', 'if', 'ifa', 'ig', 'iga', 'ih', 'iha', 'ii', 'iia', 'ij', 'ija', 'ik', 'ika', 'il', 'ila', 'im', 'ima', 'in', 'ina', 'io', 'ioa', 'ip', 'ipa', 'iq', 'iqa', 'ir', 'ira', 'is', 'isa', 'it', 'ita', 'iu', 'iua', 'iv', 'iva', 'iw', 'iwa', 'ix', 'ixa', 'iy', 'iya', 'iz', 'iza', 'j', 'ja', 'jaa', 'jab', 'jac', 'jad', 'jae', 'jaf', 'jag', 'jah', 'jai', 'jaj', 'jak', 'jal', 'jam', 'jan', 'jao', 'jap', 'jaq', 'jar', 'jas', 'jat', 'jau', 'jav', 'jaw', 'jax', 'jay', 'jaz', 'jb', 'jba', 'jc', 'jca', 'jd', 'jda', 'je', 'jea', 'jf', 'jfa', 'jg', 'jga', 'jh', 'jha', 'ji', 'jia', 'jj', 'jja', 'jk', 'jka', 'jl', 'jla', 'jm', 'jma', 'jn', 'jna', 'jo', 'joa', 'jp', 'jpa', 'jq', 'jqa', 'jr', 'jra', 'js', 'jsa', 'jt', 'jta', 'ju', 'jua', 'jv', 'jva', 'jw', 'jwa', 'jx', 'jxa', 'jy', 'jya', 'jz', 'jza', 'k', 'ka', 'kaa', 'kab', 'kac', 'kad', 'kae', 'kaf', 'kag', 'kah', 'kai', 'kaj', 'kak', 'kal', 'kam', 'kan', 'kao', 'kap', 'kaq', 'kar', 'kas', 'kat', 'kau', 'kav', 'kaw', 'kax', 'kay', 'kaz', 'kb', 'kba', 'kc', 'kca', 'kd', 'kda', 'ke', 'kea', 'kf', 'kfa', 'kg', 'kga', 'kh', 'kha', 'ki', 'kia', 'kj', 'kja', 'kk', 'kka', 'kl', 'kla', 'km', 'kma', 'kn', 'kna', 'ko', 'koa', 'kp', 'kpa', 'kq', 'kqa', 'kr', 'kra', 'ks', 'ksa', 'kt', 'kta', 'ku', 'kua', 'kv', 'kva', 'kw', 'kwa', 'kx', 'kxa', 'ky', 'kya', 'kz', 'kza', 'l', 'la', 'laa', 'lab', 'lac', 'lad', 'lae', 'laf', 'lag', 'lah', 'lai', 'laj', 'lak', 'lal', 'lam', 'lan', 'lao', 'lap', 'laq', 'lar', 'las', 'lat', 'lau', 'lav', 'law', 'lax', 'lay', 'laz', 'lb', 'lba', 'lc', 'lca', 'ld', 'lda', 'le', 'lea', 'lf', 'lfa', 'lg', 'lga', 'lh', 'lha', 'li', 'lia', 'lj', 'lja', 'lk', 'lka', 'll', 'lla', 'lm', 'lma', 'ln', 'lna', 'lo', 'loa', 'lp', 'lpa', 'lq', 'lqa', 'lr', 'lra', 'ls', 'lsa', 'lt', 'lta', 'lu', 'lua', 'lv', 'lva', 'lw', 'lwa', 'lx', 'lxa', 'ly', 'lya', 'lz', 'lza', 'm', 'ma', 'maa', 'mab', 'mac', 'mad', 'mae', 'maf', 'mag', 'mah', 'mai', 'maj', 'mak', 'mal', 'mam', 'man', 'mao', 'map', 'maq', 'mar', 'mas', 'mat', 'mau', 'mav', 'maw', 'max', 'may', 'maz', 'mb', 'mba', 'mc', 'mca', 'md', 'mda', 'me', 'mea', 'mf', 'mfa', 'mg', 'mga', 'mh', 'mha', 'mi', 'mia', 'mj', 'mja', 'mk', 'mka', 'ml', 'mla', 'mm', 'mma', 'mn', 'mna', 'mo', 'moa', 'mp', 'mpa', 'mq', 'mqa', 'mr', 'mra', 'ms', 'msa', 'mt', 'mta', 'mu', 'mua', 'mv', 'mva', 'mw', 'mwa', 'mx', 'mxa', 'my', 'mya', 'mz', 'mza', 'n', 'na', 'naa', 'nab', 'nac', 'nad', 'nae', 'naf', 'nag', 'nah', 'nai', 'naj', 'nak', 'nal', 'nam', 'nan', 'nao', 'nap', 'naq', 'nar', 'nas', 'nat', 'nau', 'nav', 'naw', 'nax', 'nay', 'naz', 'nb', 'nba', 'nc', 'nca', 'nd', 'nda', 'ne', 'nea', 'nf', 'nfa', 'ng', 'nga', 'nh', 'nha', 'ni', 'nia', 'nj', 'nja', 'nk', 'nka', 'nl', 'nla', 'nm', 'nma', 'nn', 'nna', 'no', 'noa', 'np', 'npa', 'nq', 'nqa', 'nr', 'nra', 'ns', 'nsa', 'nt', 'nta', 'nu', 'nua', 'nv', 'nva', 'nw', 'nwa', 'nx', 'nxa', 'ny', 'nya', 'nz', 'nza', 'o', 'oa', 'oaa', 'oab', 'oac', 'oad', 'oae', 'oaf', 'oag', 'oah', 'oai', 'oaj', 'oak', 'oal', 'oam', 'oan', 'oao', 'oap', 'oaq', 'oar', 'oas', 'oat', 'oau', 'oav', 'oaw', 'oax', 'oay', 'oaz', 'ob', 'oba', 'oc', 'oca', 'od', 'oda', 'oe', 'oea', 'of', 'ofa', 'og', 'oga', 'oh', 'oha', 'oi', 'oia', 'oj', 'oja', 'ok', 'oka', 'ol', 'ola', 'om', 'oma', 'on', 'ona', 'oo', 'ooa', 'op', 'opa', 'oq', 'oqa', 'or', 'ora', 'os', 'osa', 'ot', 'ota', 'ou', 'oua', 'ov', 'ova', 'ow', 'owa', 'ox', 'oxa', 'oy', 'oya', 'oz', 'oza', 'p', 'pa', 'paa', 'pab', 'pac', 'pad', 'pae', 'paf', 'pag', 'pah', 'pai', 'paj', 'pak', 'pal', 'pam', 'pan', 'pao', 'pap', 'paq', 'par', 'pas', 'pat', 'pau', 'pav', 'paw', 'pax', 'pay', 'paz', 'pb', 'pba', 'pc', 'pca', 'pd', 'pda', 'pe', 'pea', 'pf', 'pfa', 'pg', 'pga', 'ph', 'pha', 'pi', 'pia', 'pj', 'pja', 'pk', 'pka', 'pl', 'pla', 'pm', 'pma', 'pn', 'pna', 'po', 'poa', 'pp', 'ppa', 'pq', 'pqa', 'pr', 'pra', 'ps', 'psa', 'pt', 'pta', 'pu', 'pua', 'pv', 'pva', 'pw', 'pwa', 'px', 'pxa', 'py', 'pya', 'pz', 'pza', 'q', 'qa', 'qaa', 'qab', 'qac', 'qad', 'qae', 'qaf', 'qag', 'qah', 'qai', 'qaj', 'qak', 'qal', 'qam', 'qan', 'qao', 'qap', 'qaq', 'qar', 'qas', 'qat', 'qau', 'qav', 'qaw', 'qax', 'qay', 'qaz', 'qb', 'qba', 'qc', 'qca', 'qd', 'qda', 'qe', 'qea', 'qf', 'qfa', 'qg', 'qga', 'qh', 'qha', 'qi', 'qia', 'qj', 'qja', 'qk', 'qka', 'ql', 'qla', 'qm', 'qma', 'qn', 'qna', 'qo', 'qoa', 'qp', 'qpa', 'qq', 'qqa', 'qr', 'qra', 'qs', 'qsa', 'qt', 'qta', 'qu', 'qua', 'qv', 'qva', 'qw', 'qwa', 'qx', 'qxa', 'qy', 'qya', 'qz', 'qza', 'r', 'ra', 'raa', 'rab', 'rac', 'rad', 'rae', 'raf', 'rag', 'rah', 'rai', 'raj', 'rak', 'ral', 'ram', 'ran', 'rao', 'rap', 'raq', 'rar', 'ras', 'rat', 'rau', 'rav', 'raw', 'rax', 'ray', 'raz', 'rb', 'rba', 'rc', 'rca', 'rd', 'rda', 're', 'rea', 'rf', 'rfa', 'rg', 'rga', 'rh', 'rha', 'ri', 'ria', 'rj', 'rja', 'rk', 'rka', 'rl', 'rla', 'rm', 'rma', 'rn', 'rna', 'ro', 'roa', 'rp', 'rpa', 'rq', 'rqa', 'rr', 'rra', 'rs', 'rsa', 'rt', 'rta', 'ru', 'rua', 'rv', 'rva', 'rw', 'rwa', 'rx', 'rxa', 'ry', 'rya', 'rz', 'rza', 's', 'sa', 'saa', 'sab', 'sac', 'sad', 'sae', 'saf', 'sag', 'sah', 'sai', 'saj', 'sak', 'sal', 'sam', 'san', 'sao', 'sap', 'saq', 'sar', 'sas', 'sat', 'sau', 'sav', 'saw', 'sax', 'say', 'saz', 'sb', 'sba', 'sc', 'sca', 'sd', 'sda', 'se', 'sea', 'sf', 'sfa', 'sg', 'sga', 'sh', 'sha', 'si', 'sia', 'sj', 'sja', 'sk', 'ska', 'sl', 'sla', 'sm', 'sma', 'sn', 'sna', 'so', 'soa', 'sp', 'spa', 'sq', 'sqa', 'sr', 'sra', 'ss', 'ssa', 'st', 'sta', 'su', 'sua', 'sv', 'sva', 'sw', 'swa', 'sx', 'sxa', 'sy', 'sya', 'sz', 'sza', 't', 'ta', 'taa', 'tab', 'tac', 'tad', 'tae', 'taf', 'tag', 'tah', 'tai', 'taj', 'tak', 'tal', 'tam', 'tan', 'tao', 'tap', 'taq', 'tar', 'tas', 'tat', 'tau', 'tav', 'taw', 'tax', 'tay', 'taz', 'tb', 'tba', 'tc', 'tca', 'td', 'tda', 'te', 'tea', 'tf', 'tfa', 'tg', 'tga', 'th', 'tha', 'ti', 'tia', 'tj', 'tja', 'tk', 'tka', 'tl', 'tla', 'tm', 'tma', 'tn', 'tna', 'to', 'toa', 'tp', 'tpa', 'tq', 'tqa', 'tr', 'tra', 'ts', 'tsa', 'tt', 'tta', 'tu', 'tua', 'tv', 'tva', 'tw', 'twa', 'tx', 'txa', 'ty', 'tya', 'tz', 'tza', 'u', 'ua', 'uaa', 'uab', 'uac', 'uad', 'uae', 'uaf', 'uag', 'uah', 'uai', 'uaj', 'uak', 'ual', 'uam', 'uan', 'uao', 'uap', 'uaq', 'uar', 'uas', 'uat', 'uau', 'uav', 'uaw', 'uax', 'uay', 'uaz', 'ub', 'uba', 'uc', 'uca', 'ud', 'uda', 'ue', 'uea', 'uf', 'ufa', 'ug', 'uga', 'uh', 'uha', 'ui', 'uia', 'uj', 'uja', 'uk', 'uka', 'ul', 'ula', 'um', 'uma', 'un', 'una', 'uo', 'uoa', 'up', 'upa', 'uq', 'uqa', 'ur', 'ura', 'us', 'usa', 'ut', 'uta', 'uu', 'uua', 'uv', 'uva', 'uw', 'uwa', 'ux', 'uxa', 'uy', 'uya', 'uz', 'uza', 'v', 'va', 'vaa', 'vab', 'vac', 'vad', 'vae', 'vaf', 'vag', 'vah', 'vai', 'vaj', 'vak', 'val', 'vam', 'van', 'vao', 'vap', 'vaq', 'var', 'vas', 'vat', 'vau', 'vav', 'vaw', 'vax', 'vay', 'vaz', 'vb', 'vba', 'vc', 'vca', 'vd', 'vda', 've', 'vea', 'vf', 'vfa', 'vg', 'vga', 'vh', 'vha', 'vi', 'via', 'vj', 'vja', 'vk', 'vka', 'vl', 'vla', 'vm', 'vma', 'vn', 'vna', 'vo', 'voa', 'vp', 'vpa', 'vq', 'vqa', 'vr', 'vra', 'vs', 'vsa', 'vt', 'vta', 'vu', 'vua', 'vv', 'vva', 'vw', 'vwa', 'vx', 'vxa', 'vy', 'vya', 'vz', 'vza', 'w', 'wa', 'waa', 'wab', 'wac', 'wad', 'wae', 'waf', 'wag', 'wah', 'wai', 'waj', 'wak', 'wal', 'wam', 'wan', 'wao', 'wap', 'waq', 'war', 'was', 'wat', 'wau', 'wav', 'waw', 'wax', 'way', 'waz', 'wb', 'wba', 'wc', 'wca', 'wd', 'wda', 'we', 'wea', 'wf', 'wfa', 'wg', 'wga', 'wh', 'wha', 'wi', 'wia', 'wj', 'wja', 'wk', 'wka', 'wl', 'wla', 'wm', 'wma', 'wn', 'wna', 'wo', 'woa', 'wp', 'wpa', 'wq', 'wqa', 'wr', 'wra', 'ws', 'wsa', 'wt', 'wta', 'wu', 'wua', 'wv', 'wva', 'ww', 'wwa', 'wx', 'wxa', 'wy', 'wya', 'wz', 'wza', 'x', 'xa', 'xaa', 'xab', 'xac', 'xad', 'xae', 'xaf', 'xag', 'xah', 'xai', 'xaj', 'xak', 'xal', 'xam', 'xan', 'xao', 'xap', 'xaq', 'xar', 'xas', 'xat', 'xau', 'xav', 'xaw', 'xax', 'xay', 'xaz', 'xb', 'xba', 'xc', 'xca', 'xd', 'xda', 'xe', 'xea', 'xf', 'xfa', 'xg', 'xga', 'xh', 'xha', 'xi', 'xia', 'xj', 'xja', 'xk', 'xka', 'xl', 'xla', 'xm', 'xma', 'xn', 'xna', 'xo', 'xoa', 'xp', 'xpa', 'xq', 'xqa', 'xr', 'xra', 'xs', 'xsa', 'xt', 'xta', 'xu', 'xua', 'xv', 'xva', 'xw', 'xwa', 'xx', 'xxa', 'xy', 'xya', 'xz', 'xza', 'y', 'ya', 'yaa', 'yab', 'yac', 'yad', 'yae', 'yaf', 'yag', 'yah', 'yai', 'yaj', 'yak', 'yal', 'yam', 'yan', 'yao', 'yap', 'yaq', 'yar', 'yas', 'yat', 'yau', 'yav', 'yaw', 'yax', 'yay', 'yaz', 'yb', 'yba', 'yc', 'yca', 'yd', 'yda', 'ye', 'yea', 'yf', 'yfa', 'yg', 'yga', 'yh', 'yha', 'yi', 'yia', 'yj', 'yja', 'yk', 'yka', 'yl', 'yla', 'ym', 'yma', 'yn', 'yna', 'yo', 'yoa', 'yp', 'ypa', 'yq', 'yqa', 'yr', 'yra', 'ys', 'ysa', 'yt', 'yta', 'yu', 'yua', 'yv', 'yva', 'yw', 'ywa', 'yx', 'yxa', 'yy', 'yya', 'yz', 'yza', 'z', 'za', 'zaa', 'zab', 'zac', 'zad', 'zae', 'zaf', 'zag', 'zah', 'zai', 'zaj', 'zak', 'zal', 'zam', 'zan', 'zao', 'zap', 'zaq', 'zar', 'zas', 'zat', 'zau', 'zav', 'zaw', 'zax', 'zay', 'zaz', 'zb', 'zba', 'zc', 'zca', 'zd', 'zda', 'ze', 'zea', 'zf', 'zfa', 'zg', 'zga', 'zh', 'zha', 'zi', 'zia', 'zj', 'zja', 'zk', 'zka', 'zl', 'zla', 'zm', 'zma', 'zn', 'zna', 'zo', 'zoa', 'zp', 'zpa', 'zq', 'zqa', 'zr', 'zra', 'zs', 'zsa', 'zt', 'zta', 'zu', 'zua', 'zv', 'zva', 'zw', 'zwa', 'zx', 'zxa', 'zy', 'zya', 'zz', 'zza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_corrections(word, probs, vocab, n=2, verbose=False):\n",
        "    '''\n",
        "    Input:\n",
        "        word: una cadena para buscar sugerencias\n",
        "        probs: diccionario de palabras y sus probabilidades\n",
        "        vocab: conjunto de palabras del vocabulario\n",
        "        n: número de correcciones deseadas\n",
        "    Output:\n",
        "        n_best: lista de tuplas con las n mejores correcciones y sus probabilidades.\n",
        "    '''\n",
        "    suggestions = []\n",
        "    n_best = []\n",
        "\n",
        "    ### START CODE HERE ###\n",
        "\n",
        "    #Step 1: create suggestions as described above\n",
        "\n",
        "    # Si la palabra ya está en el vocabulario se genera el bucle\n",
        "    if word in vocab:\n",
        "        suggestions.append(word)\n",
        "    else:\n",
        "        one_edit_words = edit_one_letter(word)\n",
        "        suggestions.extend([w for w in one_edit_words if w in vocab])\n",
        "\n",
        "        if not suggestions:\n",
        "            two_edit_words = edit_two_letters(word)\n",
        "            suggestions.extend([w for w in two_edit_words if w in vocab])\n",
        "\n",
        "    suggestions = list(set(suggestions))\n",
        "    if not suggestions:\n",
        "        suggestions.append(word)\n",
        "\n",
        "    #Step 2: determine probability of suggestions\n",
        "    # Crear una lista de duplas (palabra, probabilidad)\n",
        "    word_prob_list = []\n",
        "    for s_word in suggestions:\n",
        "        prob = probs.get(s_word, 0.0)\n",
        "        word_prob_list.append((s_word, prob))\n",
        "\n",
        "    # Ordenar por probabilidad de forma descendente\n",
        "    word_prob_list.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    #Step 3: Get all your best words and return the most probable top n_suggested words as n_best\n",
        "    # Obtener las n sugerencias\n",
        "    n_best = word_prob_list[:n]\n",
        "\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    if verbose:\n",
        "        print(\"entered word = \", word)\n",
        "        print(\"suggestions = \", suggestions)\n",
        "\n",
        "    return n_best"
      ],
      "metadata": {
        "id": "8-fPc8ufUcuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Esta es la parte donde se definen los datos del corpus y se llama a la función\n",
        "sample_vocab = {'el', 'la', 'dulcinea', 'quijote', 'sancho'}\n",
        "sample_probs = {'el': 0.1, 'la': 0.08, 'dulcinea': 0.000734, 'quijote': 0.005, 'sancho': 0.003}\n",
        "word_to_check = \"dolcinea\""
      ],
      "metadata": {
        "id": "cdrLxJ3Yjv5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_word = 'dolcinea'\n",
        "tmp_corrections = get_corrections(my_word, probs, vocab, 2, verbose=True) # keep verbose=True\n",
        "for i, word_prob in enumerate(tmp_corrections):\n",
        "    print(f\"word {i}: {word_prob[0]}, probability {word_prob[1]:.6f}\")\n",
        "\n",
        "print(\"data type of corrections {}\".format(type(tmp_corrections)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZeE_VwwScnqF",
        "outputId": "dd276875-a9d4-4d94-8edb-d6a34118fcfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entered word =  dolcinea\n",
            "suggestions =  ['dulcinea']\n",
            "word 0: dulcinea, probability 0.000734\n",
            "data type of corrections <class 'list'>\n"
          ]
        }
      ]
    }
  ]
}